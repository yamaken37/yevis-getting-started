{"content":"version 1.0\n## Copyright Broad Institute, 2017\n## This script should convert a CRAM to SAM to BAM and output a BAM, BAM Index, and validation report to a Google bucket. If you'd like to do ## this on multiple CRAMS, create a sample set in the Data tab.  \n## The reason this approach was chosen instead of converting CRAM to BAM directly using Samtools is because Samtools 1.3 produces incorrect \n## bins due to an old version of htslib included in the package. Samtools versions 1.4 & 1.5 have an NM issue that causes them to not validate ## with Picard. \n## \n## TESTED: It was tested using the Genomes in the Cloud Docker image version 2.3.1-1500064817. \n## Versions of other tools on this image at the time of testing:\n## PICARD_VER=1.1150\n## GATK34_VER=3.4-g3c929b0\n## GATK35_VER=3.5-0-g36282e4\n## GATK36_VER=3.6-44-ge7d1cd2\n## GATK4_VER=4.beta.1\n## SAMTOOLS_VER=1.3.1\n## BWA_VER=0.7.15.r1140\n## TABIX_VER=0.2.5_r1005\n## BGZIP_VER=1.3\n## SVTOOLKIT_VER=2.00-1650\n## It was tested pulling the HG38 reference Fasta and Fai.\n## Successfully tested on Cromwell version 47. Does not work on versions < v23 due to output syntax \n## Runtime parameters are optimized for Broad's Google Cloud Platform implementation. \n##\n## LICENSING : This script is released under the WDL source code license (BSD-3) (see LICENSE in https://github.com/broadinstitute/wdl). \n## Note however that the programs it calls may be subject to different licenses. Users are responsible for checking that they are authorized to run all programs before running this script. \n## Please see the docker for detailed licensing information pertaining to the included programs.\n##\n#WORKFLOW DEFINITION\nworkflow CramToBamFlow {\n  input {\n    File ref_fasta\n    File ref_fasta_index\n    File ref_dict\n    File input_cram\n    String sample_name\n    String gotc_docker = \"broadinstitute/genomes-in-the-cloud:2.3.1-1500064817\"\n    Int preemptible_tries = 3\n  }\n\n  #converts CRAM to SAM to BAM and makes BAI\n  call CramToBamTask{\n    input:\n      ref_fasta = ref_fasta,\n      ref_fasta_index = ref_fasta_index,\n      ref_dict = ref_dict,\n      input_cram = input_cram,\n      sample_name = sample_name,\n      docker_image = gotc_docker,\n      preemptible_tries = preemptible_tries\n  }\n\n  #validates Bam\n  call ValidateSamFile{\n    input:\n      input_bam = CramToBamTask.outputBam,\n      docker_image = gotc_docker,\n      preemptible_tries = preemptible_tries\n  }\n\n  #Outputs Bam, Bai, and validation report to the FireCloud data model\n  output {\n    File outputBam = CramToBamTask.outputBam\n    File outputBai = CramToBamTask.outputBai\n    File validation_report = ValidateSamFile.report\n  }\n\n}\n\n#Task Definitions\ntask CramToBamTask {\n  input {\n    # Command parameters\n    File ref_fasta\n    File ref_fasta_index\n    File ref_dict\n    File input_cram\n    String sample_name\n\n    # Runtime parameters\n    Int addtional_disk_size = 20 \n    Int machine_mem_size = 15\n    String docker_image\n    Int preemptible_tries\n  }\n    Float output_bam_size = size(input_cram, \"GB\") / 0.60\n    Float ref_size = size(ref_fasta, \"GB\") + size(ref_fasta_index, \"GB\") + size(ref_dict, \"GB\")\n    Int disk_size = ceil(size(input_cram, \"GB\") + output_bam_size + ref_size) + addtional_disk_size\n\n\n  #Calls samtools view to do the conversion\n  command {\n    set -eo pipefail\n\n    samtools view -h -T ~{ref_fasta} ~{input_cram} |\n    samtools view -b -o ~{sample_name}.bam -\n    samtools index -b ~{sample_name}.bam\n    mv ~{sample_name}.bam.bai ~{sample_name}.bai\n  }\n\n  #Run time attributes:\n  #Use a docker with samtools. Set this up as a workspace attribute.\n  #cpu of one because no multi-threading is required. This is also default, so don't need to specify.\n  #disk_size should equal input size + output size + buffer\n  runtime {\n    docker: docker_image\n    memory: machine_mem_size + \" GB\"\n    disks: \"local-disk \" + disk_size + \" HDD\"\n    preemptible: preemptible_tries\n  }\n    \n  #Outputs a BAM and BAI with the same sample name\n  output {\n    File outputBam = \"~{sample_name}.bam\"\n    File outputBai = \"~{sample_name}.bai\"\n  }\n}\n\n#Validates BAM output to ensure it wasn't corrupted during the file conversion\ntask ValidateSamFile {\n  input {\n    File input_bam\n    Int addtional_disk_size = 10\n    Int machine_mem_size = 4\n    String docker_image\n    Int preemptible_tries\n  }\n    String output_name = basename(input_bam, \".bam\") + \".validation_report\"\n    Int disk_size = ceil(size(input_bam, \"GB\")) + addtional_disk_size\n    Int command_mem_size = machine_mem_size - 1\n  command {\n    java -Xmx~{command_mem_size}G -jar /usr/gitc/picard.jar \\\n      ValidateSamFile \\\n      INPUT=~{input_bam} \\\n      OUTPUT=~{output_name} \\\n      MODE=SUMMARY \\\n      IS_BISULFITE_SEQUENCED=false \n  }\n  #Run time attributes:\n  #Use a docker with the picard.jar. Set this up as a workspace attribute.\n  #Read more about return codes here: https://github.com/broadinstitute/cromwell#continueonreturncode\n\t\truntime {\n    docker: docker_image\n    memory: machine_mem_size + \" GB\"\n    disks: \"local-disk \" + disk_size + \" HDD\"\n    preemptible: preemptible_tries\n    continueOnReturnCode: [0,1]\n  }\n  #A text file is generated that will list errors or warnings that apply. \n  output {\n    File report = \"~{output_name}\"\n  }\n}\n\n","checksum":[{"checksum":"cf77bdafd231431d3e01e7f9996c74526d40290a9d5a685ecdfebc078501e230","type":"sha256"}],"url":"https://zenodo.org/api/files/2380ea43-a236-4276-99d4-aa84fa2b3a46/cram-to-bam.wdl"}